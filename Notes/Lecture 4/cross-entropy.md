#definition 

Cross entropy between two distributions is defined as:

$$
CrossEntropy(p, {\hat p}) = - \sum_{j=1}^k p_j \log(\hat p_j)
$$

